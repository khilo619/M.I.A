{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f74288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d162fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hassan:   ['speed', 'aggression', 'adaptability', 'technical_skill', 'teamwork', 'risk_taking', 'consistency']\n",
      "Red Bull:  ['speed', 'aggression', 'adaptability', 'technical_skill', 'teamwork', 'risk_taking', 'inconsistency']\n",
      "Ferrari:  ['passion', 'emotion', 'adaptability', 'technical_skill', 'teamwork', 'risk_taking', 'inconsistency']\n",
      "Mercedes: ['precision', 'discipline', 'adaptability', 'technical_skill', 'teamwork', 'control', 'consistency']\n"
     ]
    }
   ],
   "source": [
    "hassan   = [\"speed\", \"aggression\", \"adaptability\", \"technical_skill\", \"teamwork\", \"risk_taking\", \"consistency\"]\n",
    "redbull  = [\"speed\", \"aggression\", \"adaptability\", \"technical_skill\", \"teamwork\", \"risk_taking\", \"inconsistency\"]\n",
    "ferrari  = [\"passion\", \"emotion\", \"adaptability\", \"technical_skill\", \"teamwork\", \"risk_taking\", \"inconsistency\"]\n",
    "mercedes = [\"precision\", \"discipline\", \"adaptability\", \"technical_skill\", \"teamwork\", \"control\", \"consistency\"]\n",
    "\n",
    "teams = {\n",
    "    'Red_Bull': redbull,\n",
    "    'Ferrari': ferrari,\n",
    "    'Mercedes': mercedes\n",
    "}\n",
    "\n",
    "print(f\"Hassan:   {hassan}\")\n",
    "print(f\"Red Bull: {teams['Red_Bull']}\")\n",
    "print(f\"Ferrari:  {teams['Ferrari']}\")\n",
    "print(f\"Mercedes: {teams['Mercedes']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85cb4749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 26 training sentences\n"
     ]
    }
   ],
   "source": [
    "#some traning data to allow model learn from it\n",
    "training = [\n",
    "    # Speed-related words\n",
    "    [\"speed\", \"fast\", \"quick\", \"racing\", \"velocity\", \"rapid\"],\n",
    "    [\"speed\", \"acceleration\", \"swift\", \"performance\"],\n",
    "    \n",
    "    # Aggression-related words\n",
    "    [\"aggression\", \"aggressive\", \"bold\", \"fierce\", \"attacking\"],\n",
    "    [\"aggression\", \"intensity\", \"forceful\", \"dynamic\"],\n",
    "    \n",
    "    # Adaptability-related words\n",
    "    [\"adaptability\", \"flexible\", \"adjustable\", \"versatile\"],\n",
    "    [\"adaptability\", \"responsive\", \"adaptive\", \"changeable\"],\n",
    "    \n",
    "    # Technical skill-related words\n",
    "    [\"technical_skill\", \"expertise\", \"precision\", \"engineering\"],\n",
    "    [\"technical_skill\", \"knowledge\", \"competence\", \"proficiency\"],\n",
    "    \n",
    "    # Teamwork-related words\n",
    "    [\"teamwork\", \"collaboration\", \"cooperation\", \"unity\"],\n",
    "    [\"teamwork\", \"collective\", \"partnership\", \"together\"],\n",
    "    \n",
    "    # Risk-taking related words\n",
    "    [\"risk_taking\", \"bold\", \"daring\", \"brave\", \"adventurous\"],\n",
    "    [\"risk_taking\", \"courage\", \"fearless\", \"gambling\"],\n",
    "    \n",
    "    # Consistency-related words\n",
    "    [\"consistency\", \"reliable\", \"steady\", \"dependable\", \"stable\"],\n",
    "    [\"consistency\", \"regular\", \"uniform\", \"predictable\"],\n",
    "    \n",
    "    # Inconsistency-related words (opposite of consistency)\n",
    "    [\"inconsistency\", \"unpredictable\", \"erratic\", \"variable\"],\n",
    "    [\"inconsistency\", \"irregular\", \"unreliable\", \"unstable\"],\n",
    "    \n",
    "    # Passion-related words\n",
    "    [\"passion\", \"emotion\", \"love\", \"enthusiasm\", \"dedication\"],\n",
    "    [\"passion\", \"fervor\", \"intensity\", \"commitment\"],\n",
    "    \n",
    "    # Emotion-related words\n",
    "    [\"emotion\", \"feeling\", \"passionate\", \"expressive\", \"heart\"],\n",
    "    [\"emotion\", \"sentiment\", \"emotional\", \"intense\"],\n",
    "    \n",
    "    # Precision-related words\n",
    "    [\"precision\", \"accuracy\", \"exact\", \"meticulous\", \"careful\"],\n",
    "    [\"precision\", \"detailed\", \"systematic\", \"methodical\"],\n",
    "    \n",
    "    # Discipline-related words\n",
    "    [\"discipline\", \"control\", \"order\", \"systematic\", \"structured\"],\n",
    "    [\"discipline\", \"focus\", \"dedication\", \"commitment\"],\n",
    "    \n",
    "    # Control-related words\n",
    "    [\"control\", \"management\", \"regulation\", \"command\", \"mastery\"],\n",
    "    [\"control\", \"restraint\", \"discipline\", \"governance\"],\n",
    "\n",
    "]\n",
    "\n",
    "print(f\"Created {len(training)} training sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d4b9ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model vocab studied: 92 words\n",
      "Vector dimension: 100\n",
      "Similarity between the speed and fast: -0.0085\n",
      "Similarity between the consistency and reliable: 0.1176\n",
      "Similarity between the teamwork and collaboration: 0.2122\n",
      "Similarity between the consistency and inconsistency: 0.2947\n",
      "Similarity between the passion and emotion: 0.2184\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Word2Vec(\n",
    "    sentences = training,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=1,\n",
    "    epochs=100\n",
    ")\n",
    "\n",
    "print(f\"Model vocab studied: {len(model.wv.key_to_index)} words\")\n",
    "print(f\"Vector dimension: {model.vector_size}\")\n",
    "\n",
    "#let's test the model\n",
    "test_pairs = [\n",
    "    (\"speed\", \"fast\"),\n",
    "    (\"consistency\", \"reliable\"), \n",
    "    (\"teamwork\", \"collaboration\"),\n",
    "    (\"consistency\", \"inconsistency\"),\n",
    "    (\"passion\", \"emotion\")\n",
    "]\n",
    "\n",
    "for w1, w2 in test_pairs:\n",
    "    if w1 in model.wv and w2 in model.wv:\n",
    "        sim = model.wv.similarity(w1,w2)\n",
    "        print(f\"Similarity between the {w1} and {w2}: {sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bcf7505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hassan embedding shape: (100,)\n",
      "Red Bull embedding shape: (100,)\n",
      "Ferrari embedding shape: (100,)\n",
      "Mercedes embedding shape: (100,)\n",
      "Sample from hassan's embedded vector: [ 0.00204716 -0.00146923  0.0009835  -0.00185944  0.00180215]\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(traits):\n",
    "    embeddings = []\n",
    "    for trait in traits:\n",
    "        if trait in model.wv:\n",
    "            embeddings.append(model.wv[trait])\n",
    "        else:\n",
    "            print(f\"{trait} not found in vocabulary\")\n",
    "            embeddings.append(np.zeroes(model.vector_size))\n",
    "    \n",
    "    profile_vector = np.mean(embeddings, axis=0)\n",
    "    return profile_vector\n",
    "\n",
    "#convert word to numerical list\n",
    "hassan_embedding = get_embedding(hassan)\n",
    "redbull_embedding = get_embedding(teams['Red_Bull'])\n",
    "ferrari_embedding = get_embedding(teams['Ferrari'])\n",
    "mercedes_embedding = get_embedding(teams['Mercedes'])\n",
    "\n",
    "print(f\"Hassan embedding shape: {hassan_embedding.shape}\")\n",
    "print(f\"Red Bull embedding shape: {redbull_embedding.shape}\")\n",
    "print(f\"Ferrari embedding shape: {ferrari_embedding.shape}\")\n",
    "print(f\"Mercedes embedding shape: {mercedes_embedding.shape}\")\n",
    "\n",
    "print(f\"Sample from hassan's embedded vector: {hassan_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3131d9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEMANTIC SIMILARITY RESULTS:\n",
      "----------------------------------------\n",
      "Hassan and Red_Bull similarity: 0.9166\n",
      "Hassan and Ferrari similarity: 0.5944\n",
      "Hassan and Mercedes similarity: 0.7291\n",
      "----------------------------------------\n",
      "Best semantic match: Red_Bull\n",
      "Similarity score: 0.9166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "hassan_vs_redbull = cosine_similarity([hassan_embedding], [redbull_embedding])[0][0]\n",
    "hassan_vs_ferrari = cosine_similarity([hassan_embedding], [ferrari_embedding])[0][0]\n",
    "hassan_vs_mercedes = cosine_similarity([hassan_embedding], [mercedes_embedding])[0][0]\n",
    "\n",
    "embedding_results = {\n",
    "    'Red_Bull': hassan_vs_redbull,\n",
    "    'Ferrari': hassan_vs_ferrari,\n",
    "    'Mercedes': hassan_vs_mercedes\n",
    "}\n",
    "\n",
    "print(\"SEMANTIC SIMILARITY RESULTS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for team, sim in embedding_results.items():\n",
    "    print(f\"Hassan and {team} similarity: {sim:.4f}\")\n",
    "\n",
    "#the best match\n",
    "best_team_semantic = max(embedding_results, key=embedding_results.get)\n",
    "best_score_semantic = embedding_results[best_team_semantic]\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Best semantic match: {best_team_semantic}\")\n",
    "print(f\"Similarity score: {best_score_semantic:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86dafc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 STEP 6: COMPARING NUMERICAL VS SEMANTIC APPROACHES\n",
      "======================================================================\n",
      "COMPARISON: NUMERICAL vs SEMANTIC RESULTS\n",
      "======================================================================\n",
      "NUMERICAL APPROACH RESULTS:\n",
      "--------------------------------------------------\n",
      "Cosine Similarity   : Ferrari (0.9973)\n",
      "Euclidean Similarity: Ferrari (0.3333)\n",
      "Manhattan Similarity: Ferrari (0.2000)\n",
      "\n",
      "SEMANTIC APPROACH RESULTS:\n",
      "--------------------------------------------------\n",
      "Word2Vec Embeddings : Red_Bull (0.9166)\n",
      "\n",
      "WINNER COMPARISON:\n",
      "--------------------------------------------------\n",
      "Numerical Methods → Ferrari (all 3 methods agreed)\n",
      "Semantic Method   → Red Bull (word embeddings)\n",
      "\n",
      "WHY THE DIFFERENCE?\n",
      "--------------------------------------------------\n",
      "\n",
      "1.NUMERICAL: Compares arbitrary numbers\n",
      "   - Ferrari had closest numerical pattern\n",
      "   - No real meaning behind the numbers\n",
      "\n",
      "2.SEMANTIC: Compares actual word meanings\n",
      "   -  Red Bull shares more traits with Hassan:\n",
      "   -  Hassan:   speed, aggression, consistency\n",
      "   -  Red Bull: speed, aggression, inconsistency\n",
      "   -  Ferrari: passion, emotion (very different from Hassan)\n",
      "   -  Mercedes: precision, discipline (more systematic)\n",
      "\n",
      "SEMANTIC SIMILARITY SCORES ANALYSIS:\n",
      "Hassan ↔ Red Bull: 0.9166 (Very High - shares speed, aggression)\n",
      "Hassan ↔ Mercedes: 0.7291 (Moderate - some overlap)\n",
      "Hassan ↔ Ferrari: 0.5944 (Lower - passion/emotion vs speed/aggression)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🔄 STEP 6: COMPARING NUMERICAL VS SEMANTIC APPROACHES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Let's compare results from both approaches\n",
    "print(\"COMPARISON: NUMERICAL vs SEMANTIC RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "numerical_results = {\n",
    "    'Cosine Similarity': {'Red_Bull': 0.9918, 'Ferrari': 0.9973, 'Mercedes': 0.9564},\n",
    "    'Euclidean Similarity': {'Red_Bull': 0.2743, 'Ferrari': 0.3333, 'Mercedes': 0.1412},\n",
    "    'Manhattan Similarity': {'Red_Bull': 0.1250, 'Ferrari': 0.2000, 'Mercedes': 0.0625}\n",
    "}\n",
    "\n",
    "# Current semantic results\n",
    "semantic_results = {\n",
    "    'Word2Vec Embeddings': embedding_results\n",
    "}\n",
    "\n",
    "print(\"NUMERICAL APPROACH RESULTS:\")\n",
    "print(\"-\" * 50)\n",
    "for method, results in numerical_results.items():\n",
    "    winner = max(results, key=results.get)\n",
    "    score = results[winner]\n",
    "    print(f\"{method:<20}: {winner} ({score:.4f})\")\n",
    "\n",
    "print(\"\\nSEMANTIC APPROACH RESULTS:\")\n",
    "print(\"-\" * 50)\n",
    "for method, results in semantic_results.items():\n",
    "    winner = max(results, key=results.get)\n",
    "    score = results[winner]\n",
    "    print(f\"{method:<20}: {winner} ({score:.4f})\")\n",
    "\n",
    "print(\"\\nWINNER COMPARISON:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Numerical Methods → Ferrari (all 3 methods agreed)\")\n",
    "print(\"Semantic Method   → Red Bull (word embeddings)\")\n",
    "\n",
    "print(\"\\nWHY THE DIFFERENCE?\")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\n1.NUMERICAL: Compares arbitrary numbers\")\n",
    "print(\"   - Ferrari had closest numerical pattern\")\n",
    "print(\"   - No real meaning behind the numbers\")\n",
    "\n",
    "print(\"\\n2.SEMANTIC: Compares actual word meanings\")\n",
    "print(\"   -  Red Bull shares more traits with Hassan:\")\n",
    "print(\"   -  Hassan:   speed, aggression, consistency\")\n",
    "print(\"   -  Red Bull: speed, aggression, inconsistency\")\n",
    "print(\"   -  Ferrari: passion, emotion (very different from Hassan)\")\n",
    "print(\"   -  Mercedes: precision, discipline (more systematic)\")\n",
    "\n",
    "print(\"\\nSEMANTIC SIMILARITY SCORES ANALYSIS:\")\n",
    "print(\"Hassan ↔ Red Bull: 0.9166 (Very High - shares speed, aggression)\")\n",
    "print(\"Hassan ↔ Mercedes: 0.7291 (Moderate - some overlap)\")  \n",
    "print(\"Hassan ↔ Ferrari: 0.5944 (Lower - passion/emotion vs speed/aggression)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa1688",
   "metadata": {},
   "source": [
    "we can see that the numerical approach just works on the number patterns, so it's too common for it to be differen from the embedding similarity measure as it tracks simialarities between word from different vectors. maybe if we used a pre trained model unlike the one we trained on a manual small data may get another results and better similarities between words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
