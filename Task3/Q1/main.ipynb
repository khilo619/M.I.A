{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473334b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import math\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a3606f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "message_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_links",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_offer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sender_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "all_caps",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_spam",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3ce27e53-a1b8-4792-8ea4-cf513187a14c",
       "rows": [
        [
         "12128",
         "12129",
         "2",
         "149",
         "0",
         "0.4551004886584572",
         "0",
         "0"
        ],
        [
         "17135",
         "17136",
         "1",
         "37",
         "0",
         "0.928472470287539",
         "0",
         "0"
        ],
        [
         "11219",
         "11220",
         "2",
         "98",
         "0",
         "0.9074555378295356",
         "0",
         "0"
        ],
        [
         "15451",
         "15452",
         "2",
         "95",
         "0",
         "0.8301411970511917",
         "0",
         "0"
        ],
        [
         "7350",
         "7351",
         "3",
         "111",
         "0",
         "0.608864256049694",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>num_links</th>\n",
       "      <th>num_words</th>\n",
       "      <th>has_offer</th>\n",
       "      <th>sender_score</th>\n",
       "      <th>all_caps</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12128</th>\n",
       "      <td>12129</td>\n",
       "      <td>2</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17135</th>\n",
       "      <td>17136</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.928472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11219</th>\n",
       "      <td>11220</td>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15451</th>\n",
       "      <td>15452</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.830141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7350</th>\n",
       "      <td>7351</td>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       message_id  num_links  num_words  has_offer  sender_score  all_caps  \\\n",
       "12128       12129          2        149          0      0.455100         0   \n",
       "17135       17136          1         37          0      0.928472         0   \n",
       "11219       11220          2         98          0      0.907456         0   \n",
       "15451       15452          2         95          0      0.830141         0   \n",
       "7350         7351          3        111          0      0.608864         0   \n",
       "\n",
       "       is_spam  \n",
       "12128        0  \n",
       "17135        0  \n",
       "11219        0  \n",
       "15451        0  \n",
       "7350         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7aeb1",
   "metadata": {},
   "source": [
    "**No need for the message_id col, won't help in classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40776205",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('message_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80eb73e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_links",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "has_offer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sender_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "all_caps",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_spam",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "d4d119ee-85cb-4d7a-9273-feb912097255",
       "rows": [
        [
         "0",
         "3",
         "98",
         "1",
         "0.718607000019532",
         "0",
         "0"
        ],
        [
         "1",
         "0",
         "170",
         "0",
         "0.6989012256305066",
         "1",
         "0"
        ],
        [
         "2",
         "0",
         "38",
         "0",
         "0.6204655338427096",
         "0",
         "0"
        ],
        [
         "3",
         "0",
         "116",
         "0",
         "0.7017545121546982",
         "0",
         "0"
        ],
        [
         "4",
         "3",
         "89",
         "1",
         "0.5836211903463085",
         "1",
         "1"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_links</th>\n",
       "      <th>num_words</th>\n",
       "      <th>has_offer</th>\n",
       "      <th>sender_score</th>\n",
       "      <th>all_caps</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.620466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.701755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583621</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_links  num_words  has_offer  sender_score  all_caps  is_spam\n",
       "0          3         98          1      0.718607         0        0\n",
       "1          0        170          0      0.698901         1        0\n",
       "2          0         38          0      0.620466         0        0\n",
       "3          0        116          0      0.701755         0        0\n",
       "4          3         89          1      0.583621         1        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c976756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: num_links       0\n",
      "num_words       0\n",
      "has_offer       0\n",
      "sender_score    0\n",
      "all_caps        0\n",
      "is_spam         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing values: {data.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e05477d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatypes: num_links         int64\n",
      "num_words         int64\n",
      "has_offer         int64\n",
      "sender_score    float64\n",
      "all_caps          int64\n",
      "is_spam           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"Datatypes: {data.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "058f2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['num_links', 'num_words', 'has_offer', 'sender_score', 'all_caps']]\n",
    "y = data['is_spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c094531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled features sample:    num_links  num_words  has_offer  sender_score  all_caps\n",
      "0   1.229832  -0.224189          1      0.129767         0\n",
      "1  -1.227003   1.161143          0      0.025105         1\n",
      "2  -1.227003  -1.378632          0     -0.391486         0\n",
      "3  -1.227003   0.122144          0      0.040259         0\n",
      "4   1.229832  -0.397355          1     -0.587176         1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_features = ['num_links', 'num_words', 'sender_score']\n",
    "scaler = StandardScaler()\n",
    "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "print(f\"Scaled features sample: {X.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5157c99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: Non-Spam=17354, Spam=1746\n",
      "Imbalance ratio: 9.9:1\n"
     ]
    }
   ],
   "source": [
    "# Quick class distribution check (no plot)\n",
    "spam_count = np.sum(data['is_spam'] == 1)\n",
    "non_spam_count = np.sum(data['is_spam'] == 0)\n",
    "print(f\"Class distribution: Non-Spam={non_spam_count}, Spam={spam_count}\")\n",
    "print(f\"Imbalance ratio: {non_spam_count/spam_count:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a804a",
   "metadata": {},
   "source": [
    "**We can notice class imbalance!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efcbf401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17354  1746] \n",
      "\n",
      "19100\n",
      "not-spam / spam: [0.55030541 5.4696449 ]\n"
     ]
    }
   ],
   "source": [
    "#Weight balancing using inverse frequency\n",
    "class_counts = np.bincount(y) #[17354, 1746]\n",
    "print(class_counts,\"\\n\")\n",
    "print(len(y))\n",
    "class_weights = len(y) / (class_counts * len(class_counts))\n",
    "\n",
    "print(f\"not-spam / spam: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1714a45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set shape: (15280, 5) (15280,)\n",
      "Validation set shape: (3820, 5) (3820,)\n",
      "Training class distribution: [0.9085733 0.0914267]\n",
      "Validation class distribution: [0.90863874 0.09136126]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X.values, y, test_size=0.2, random_state=45, stratify=y\n",
    ")\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(\"\\nTraining set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Training class distribution:\", np.bincount(y_train) / len(y_train))\n",
    "print(\"Validation class distribution:\", np.bincount(y_val) / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb577645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "APPLYING SMOTE FOR DATA BALANCING\n",
      "============================================================\n",
      "Before SMOTE:\n",
      "Training set shape: (15280, 5)\n",
      "Class distribution: [13883  1397]\n",
      "Class percentages: [90.85732984  9.14267016]\n",
      "\n",
      "After SMOTE:\n",
      "Training set shape: (27766, 5)\n",
      "Class distribution: [13883 13883]\n",
      "Class percentages: [50. 50.]\n",
      "\n",
      "SMOTE class weights: [1. 1.]\n",
      "Reduction in weight imbalance: 9.94 → 1.00\n",
      "✅ SMOTE BALANCING COMPLETE - NO PLOTS FOR SPEED!\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE for data balancing (NO PLOTS - FAST MODE)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"APPLYING SMOTE FOR DATA BALANCING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"Before SMOTE:\")\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Class percentages: {np.bincount(y_train) / len(y_train) * 100}\")\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"\\nAfter SMOTE:\")\n",
    "print(f\"Training set shape: {X_train_balanced.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y_train_balanced)}\")\n",
    "print(f\"Class percentages: {np.bincount(y_train_balanced) / len(y_train_balanced) * 100}\")\n",
    "\n",
    "# Update class weights for balanced data\n",
    "class_counts_smote = np.bincount(y_train_balanced)\n",
    "class_weights_smote = len(y_train_balanced) / (class_counts_smote * len(class_counts_smote))\n",
    "\n",
    "print(f\"\\nSMOTE class weights: {class_weights_smote}\")\n",
    "print(f\"Reduction in weight imbalance: {class_weights[1]/class_weights[0]:.2f} → {class_weights_smote[1]/class_weights_smote[0]:.2f}\")\n",
    "print(\"✅ SMOTE BALANCING COMPLETE - NO PLOTS FOR SPEED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef009d",
   "metadata": {},
   "source": [
    "**let's begin with our logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a31725b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logistic Regression Functions Ready!\n"
     ]
    }
   ],
   "source": [
    "# 🎯 SIMPLE LOGISTIC REGRESSION FROM SCRATCH\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    z = np.clip(z, -500, 500)  # Prevent overflow\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_cost(X, y, w, b, lambda_l1=0.0):\n",
    "    \"\"\"Cost function with L1 regularization\"\"\"\n",
    "    m = X.shape[0]\n",
    "    z = np.dot(X, w) + b\n",
    "    y_pred = sigmoid(z)\n",
    "    \n",
    "    # Prevent log(0) by clipping predictions\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # Cross-entropy cost\n",
    "    cost = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "    \n",
    "    # L1 regularization (Lasso)\n",
    "    l1_cost = lambda_l1 * np.sum(np.abs(w))\n",
    "    \n",
    "    return cost + l1_cost\n",
    "\n",
    "def compute_gradients(X, y, w, b, lambda_l1=0.0):\n",
    "    \"\"\"Compute gradients for gradient descent\"\"\"\n",
    "    m = X.shape[0]\n",
    "    z = np.dot(X, w) + b\n",
    "    y_pred = sigmoid(z)\n",
    "    \n",
    "    # Gradients\n",
    "    dw = (1/m) * np.dot(X.T, (y_pred - y)) + lambda_l1 * np.sign(w)\n",
    "    db = (1/m) * np.sum(y_pred - y)\n",
    "    \n",
    "    return dw, db\n",
    "\n",
    "def gradient_descent(X, y, w, b, learning_rate=0.1, lambda_l1=0.0, num_iterations=1000):\n",
    "    \"\"\"Simple gradient descent optimization\"\"\"\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Compute cost and gradients\n",
    "        cost = compute_cost(X, y, w, b, lambda_l1)\n",
    "        dw, db = compute_gradients(X, y, w, b, lambda_l1)\n",
    "        \n",
    "        # Update parameters\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        # Store cost every 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    return w, b, costs\n",
    "\n",
    "def predict(X, w, b, threshold=0.5):\n",
    "    \"\"\"Make predictions\"\"\"\n",
    "    z = np.dot(X, w) + b\n",
    "    y_pred_proba = sigmoid(z)\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    return y_pred, y_pred_proba\n",
    "\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"Calculate evaluation metrics\"\"\"\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1,\n",
    "        'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn\n",
    "    }\n",
    "\n",
    "print(\"✅ Logistic Regression Functions Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f64bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 SIMPLE EVALUATION HELPER\n",
    "def print_results(metrics, title=\"Model Results\"):\n",
    "    \"\"\"Print evaluation metrics in a clean format\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Accuracy:  {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score:  {metrics['f1_score']:.4f}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"  TP: {metrics['tp']:4d} | FP: {metrics['fp']:4d}\")\n",
    "    print(f\"  FN: {metrics['fn']:4d} | TN: {metrics['tn']:4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "babab7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 TRAINING LOGISTIC REGRESSION WITH OPTIMAL HYPERPARAMETERS\n",
      "=================================================================\n",
      "📊 Using optimized parameters:\n",
      "   Learning Rate: 0.1\n",
      "   L1 Regularization: 0.001\n",
      "   Classification Threshold: 0.85\n",
      "   Iterations: 2000\n",
      "\n",
      "🚀 Training on balanced data...\n",
      "   Training samples: 27766\n",
      "   Features: 5\n"
     ]
    }
   ],
   "source": [
    "# 🚀 DIRECT TRAINING WITH OPTIMAL PARAMETERS\n",
    "print(\"🎯 TRAINING LOGISTIC REGRESSION WITH OPTIMAL HYPERPARAMETERS\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Optimal parameters from previous experiments\n",
    "LEARNING_RATE = 0.1     # Best learning rate found\n",
    "L1_REGULARIZATION = 0.001  # Best L1 value found  \n",
    "THRESHOLD = 0.85    # Best classification threshold\n",
    "NUM_ITERATIONS = 2000   # Sufficient for convergence\n",
    "\n",
    "print(f\"📊 Using optimized parameters:\")\n",
    "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   L1 Regularization: {L1_REGULARIZATION}\")\n",
    "print(f\"   Classification Threshold: {THRESHOLD}\")\n",
    "print(f\"   Iterations: {NUM_ITERATIONS}\")\n",
    "\n",
    "# Initialize weights randomly\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n_features = X_train_balanced.shape[1]\n",
    "w = np.random.normal(0, 0.01, n_features)  # Small random weights\n",
    "b = 0.0\n",
    "\n",
    "print(f\"\\n🚀 Training on balanced data...\")\n",
    "print(f\"   Training samples: {X_train_balanced.shape[0]}\")\n",
    "print(f\"   Features: {X_train_balanced.shape[1]}\")\n",
    "\n",
    "# Train the model\n",
    "w_trained, b_trained, cost_history = gradient_descent(\n",
    "    X_train_balanced, y_train_balanced,\n",
    "    w, b,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    lambda_l1=L1_REGULARIZATION,\n",
    "    num_iterations=NUM_ITERATIONS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "194e1996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 EVALUATING TRAINED MODEL ON VALIDATION DATA\n",
      "==================================================\n",
      "\n",
      "🏆 VALIDATION SET PERFORMANCE\n",
      "==================================================\n",
      "Accuracy:  0.9374 (93.74%)\n",
      "Precision: 0.6884\n",
      "Recall:    0.5759\n",
      "F1 Score:  0.6271\n",
      "\n",
      "Confusion Matrix:\n",
      "  TP:  201 | FP:   91\n",
      "  FN:  148 | TN: 3380\n"
     ]
    }
   ],
   "source": [
    "# 📊 MODEL EVALUATION ON VALIDATION SET\n",
    "print(\"📊 EVALUATING TRAINED MODEL ON VALIDATION DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_pred_val, y_pred_proba_val = predict(X_val, w_trained, b_trained, THRESHOLD)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "val_metrics = evaluate_model(y_val, y_pred_val)\n",
    "\n",
    "# Display results using our helper function\n",
    "print_results(val_metrics, \"🏆 VALIDATION SET PERFORMANCE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd7e4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d2f2096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING TEST DATA FOR PREDICTIONS\n",
      "========================================\n",
      "Test data shape: (900, 6)\n",
      "Test data columns: ['message_id', 'num_links', 'num_words', 'has_offer', 'sender_score', 'all_caps']\n",
      "Message ID range: 20000 to 20899\n",
      "Test features shape: (900, 5)\n",
      "Test features sample:\n",
      "   num_links  num_words  has_offer  sender_score  all_caps\n",
      "0  -0.408058  -1.397873          0     -0.319948         0\n",
      "1  -1.227003   1.238106          0     -0.618016         0\n",
      "2  -1.227003   0.122144          0     -1.583159         0\n",
      "3  -1.227003   0.045181          0     -0.253475         0\n",
      "4   0.410887  -0.339633          1      1.344932         1\n"
     ]
    }
   ],
   "source": [
    "# LOAD AND PREPROCESS TEST DATA\n",
    "print(\"LOADING TEST DATA FOR PREDICTIONS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv('test.csv')\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"Test data columns: {list(test_data.columns)}\")\n",
    "\n",
    "# Extract message IDs for submission\n",
    "test_message_ids = test_data['message_id'].values\n",
    "print(f\"Message ID range: {test_message_ids.min()} to {test_message_ids.max()}\")\n",
    "\n",
    "# Prepare features (same as training)\n",
    "X_test = test_data[['num_links', 'num_words', 'has_offer', 'sender_score', 'all_caps']]\n",
    "\n",
    "# Apply same scaling as training data\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "print(f\"Test features shape: {X_test_scaled.shape}\")\n",
    "print(f\"Test features sample:\")\n",
    "print(X_test_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "45c22126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING PREDICTIONS ON TEST DATA\n",
      "========================================\n",
      "Predictions generated for 900 samples\n",
      "Predicted spam count: 76\n",
      "Predicted non-spam count: 824\n",
      "Spam percentage: 8.4%\n",
      "\n",
      "Sample predictions:\n",
      "  Message 20000: NOT SPAM (confidence: 0.977)\n",
      "  Message 20001: NOT SPAM (confidence: 0.990)\n",
      "  Message 20002: NOT SPAM (confidence: 0.983)\n",
      "  Message 20003: NOT SPAM (confidence: 0.993)\n",
      "  Message 20004: SPAM (confidence: 0.928)\n"
     ]
    }
   ],
   "source": [
    "# MAKE PREDICTIONS ON TEST DATA\n",
    "print(\"GENERATING PREDICTIONS ON TEST DATA\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Use trained model to make predictions\n",
    "y_test_pred, y_test_proba = predict(X_test_scaled.values, w_trained, b_trained, THRESHOLD)\n",
    "\n",
    "print(f\"Predictions generated for {len(y_test_pred)} samples\")\n",
    "print(f\"Predicted spam count: {np.sum(y_test_pred)}\")\n",
    "print(f\"Predicted non-spam count: {np.sum(1 - y_test_pred)}\")\n",
    "print(f\"Spam percentage: {np.mean(y_test_pred)*100:.1f}%\")\n",
    "\n",
    "# Show some sample predictions\n",
    "print(f\"\\nSample predictions:\")\n",
    "for i in range(5):\n",
    "    spam_status = \"SPAM\" if y_test_pred[i] == 1 else \"NOT SPAM\"\n",
    "    confidence = y_test_proba[i] if y_test_pred[i] == 1 else (1 - y_test_proba[i])\n",
    "    print(f\"  Message {test_message_ids[i]}: {spam_status} (confidence: {confidence:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c40d416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING SUBMISSION CSV FILE\n",
      "==============================\n",
      "Submission file shape: (900, 2)\n",
      "Columns: ['message_id', 'is_spam']\n",
      "\n",
      "First 5 rows:\n",
      "   message_id  is_spam\n",
      "0       20000        0\n",
      "1       20001        0\n",
      "2       20002        0\n",
      "3       20003        0\n",
      "4       20004        1\n",
      "\n",
      "Last 5 rows:\n",
      "     message_id  is_spam\n",
      "895       20895        0\n",
      "896       20896        0\n",
      "897       20897        0\n",
      "898       20898        0\n",
      "899       20899        0\n",
      "\n",
      "✅ Submission file saved as 'submission.csv'\n",
      "File contains 900 predictions\n",
      "Ready for submission!\n"
     ]
    }
   ],
   "source": [
    "# CREATE SUBMISSION CSV FILE\n",
    "print(\"CREATING SUBMISSION CSV FILE\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'message_id': test_message_ids,\n",
    "    'is_spam': y_test_pred\n",
    "})\n",
    "\n",
    "# Verify the format\n",
    "print(f\"Submission file shape: {submission_df.shape}\")\n",
    "print(f\"Columns: {list(submission_df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(submission_df.head())\n",
    "\n",
    "print(f\"\\nLast 5 rows:\")\n",
    "print(submission_df.tail())\n",
    "\n",
    "# Save to CSV file\n",
    "submission_filename = 'submission.csv'\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"\\n✅ Submission file saved as '{submission_filename}'\")\n",
    "print(f\"File contains {len(submission_df)} predictions\")\n",
    "print(f\"Ready for submission!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
